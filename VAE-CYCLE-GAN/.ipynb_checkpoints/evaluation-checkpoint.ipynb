{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "round-society",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-substitute",
   "metadata": {},
   "source": [
    "This notebook aims to evaluate the implemented VAE-CYCLE-GAN in two ways. Subjectively by generating images on test set and quantitatively by using metrics proposed by the original Cycle-GAN paper, PSNR and SSIM. We must first start by:\n",
    "\n",
    "    1. Forward passing through the network for a given pretrained model/experiment - \n",
    "    2. Get the generated mel then the reconstructed mel\n",
    "    3. Output generated mel in format for wavenet to then infer from\n",
    "    4. Plot all input, recon, output melspectrograms for test set (save to folder)\n",
    "    5. Compute reconstuction metrics between recon and original input also average\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-cradle",
   "metadata": {},
   "source": [
    "### Forward Passing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-farming",
   "metadata": {},
   "source": [
    "Loading models and instantiating with learn weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "facial-dating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (res1_2): ResidualBlock(\n",
       "    (conv1): Sequential(\n",
       "      (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "      (1): Conv2d(1024, 1024, kernel_size=(4, 4), stride=(1, 1))\n",
       "      (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (1): Conv2d(1024, 1024, kernel_size=(4, 4), stride=(1, 1))\n",
       "      (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (res1_3): ResidualBlock(\n",
       "    (conv1): Sequential(\n",
       "      (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "      (1): Conv2d(1024, 1024, kernel_size=(4, 4), stride=(1, 1))\n",
       "      (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (1): Conv2d(1024, 1024, kernel_size=(4, 4), stride=(1, 1))\n",
       "      (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (conv5): Sequential(\n",
       "    (0): ConvTranspose2d(128, 1, kernel_size=(11, 11), stride=(1, 1))\n",
       "    (1): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import load_pickle, save_pickle, show_mel, show_mel_transfer\n",
    "import itertools\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from models import Encoder, ResGen, Generator # change to models_logvar accordingly\n",
    "\n",
    "g = '1'\n",
    "device = torch.device('cuda')\n",
    "torch.cuda.set_device(int(g))\n",
    "map_location='cuda:'+g\n",
    "\n",
    "n = '65'\n",
    "path = '../pool/'+n\n",
    "\n",
    "# Model Instantiation\n",
    "enc = Encoder().to(device)  # Shared encoder model\n",
    "res = ResGen().to(device)  # Shared residual decoding block\n",
    "dec_A2B = Generator().to(device)  # Generator and Discriminator for Speaker A to B\n",
    "dec_B2A = Generator().to(device)  # Generator and Discriminator for Speaker B to A\n",
    "\n",
    "# Initialise pretrained weights\n",
    "enc.load_state_dict(torch.load(path+'/enc.pt', map_location=map_location)) \n",
    "res.load_state_dict(torch.load(path+'/res.pt', map_location=map_location)) \n",
    "dec_A2B.load_state_dict(torch.load(path+'/dec_A2B.pt', map_location=map_location))\n",
    "dec_B2A.load_state_dict(torch.load(path+'/dec_B2A.pt', map_location=map_location))\n",
    "\n",
    "enc.eval()\n",
    "res.eval()\n",
    "dec_A2B.eval()\n",
    "dec_B2A.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-brand",
   "metadata": {},
   "source": [
    "Getting text file for all path names to numpy feat files (and wav files for the matter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "organized-montana",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "test_path_A = '../WAVENET/egs/gaussian/dump/lj/logmelspectrogram/norm/eval/'\n",
    "wavmels_A = np.genfromtxt(test_path_A+'train.txt', dtype=[('wav','S50'),('mel','S50'),('nmel','i8'),('str','S27')], delimiter='|')\n",
    "\n",
    "# Only temporary\n",
    "test_path_B = '../WAVENET/egs/gaussian/dump/lj/logmelspectrogram/norm/eval_4/'\n",
    "wavmels_B = np.genfromtxt(test_path_B+'train.txt', dtype=[('wav','S50'),('mel','S50'),('nmel','i8'),('str','S27')], delimiter='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-moore",
   "metadata": {},
   "source": [
    "Defining forward inferences from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "descending-moore",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(data):\n",
    "    mel = data.data[0]\n",
    "    mel = mel.view(128, 128)\n",
    "    mel = mel.detach().cpu().numpy()\n",
    "    return mel\n",
    "\n",
    "def forward_A2B(mel_in):\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        real_mel_A = torch.from_numpy(np.array([mel_in])).to(device)\n",
    "        real_mel_A = real_mel_A.view(1, 1, 128, 128) # using batch size of 1 to return each metric\n",
    "\n",
    "        # Forward pass for A to B\n",
    "        latent_mel_A, mu_A, logvar_A = enc(real_mel_A)\n",
    "        pseudo_mel_A = res(latent_mel_A)\n",
    "        fake_mel_B = dec_A2B(pseudo_mel_A)\n",
    "\n",
    "        # Cyclic reconstuction from fake B to A\n",
    "        latent_recon_B, mu_recon_B, logvar_recon_B = enc(fake_mel_B)\n",
    "        pseudo_recon_B = res(latent_recon_B)\n",
    "        recon_mel_A = dec_B2A(pseudo_recon_B) \n",
    "    \n",
    "    return to_numpy(real_mel_A), to_numpy(recon_mel_A), to_numpy(fake_mel_B)\n",
    "\n",
    "def forward_B2A(mel_in):\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        real_mel_B = torch.from_numpy(np.array([mel_in])).to(device)\n",
    "        real_mel_B = real_mel_B.view(1, 1, 128, 128) # using batch size of 1 to return each metric\n",
    "\n",
    "        # Forward pass for B to A\n",
    "        latent_mel_B, mu_B, logvar_B = enc(real_mel_B)\n",
    "        pseudo_mel_B = res(latent_mel_B)\n",
    "        fake_mel_A = dec_B2A(pseudo_mel_B)\n",
    "\n",
    "        # Cyclic reconstuction from fake A to B\n",
    "        latent_recon_A, mu_recon_A, logvar_recon_A = enc(fake_mel_A)\n",
    "        pseudo_recon_A = res(latent_recon_A)\n",
    "        recon_mel_B = dec_A2B(pseudo_recon_A) \n",
    "    \n",
    "    return to_numpy(real_mel_B), to_numpy(recon_mel_B), to_numpy(fake_mel_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-march",
   "metadata": {},
   "source": [
    "Defining evaluation methods between recon and real mels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "narrative-department",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.metrics\n",
    "\n",
    "def compute_psnr_ssim(real_mel, recon_mel):\n",
    "    # data range set to 2 as its distance between normalised min -1 and max 1\n",
    "    psnr = skimage.metrics.peak_signal_noise_ratio(real_mel, recon_mel, data_range=2)\n",
    "    ssim = skimage.metrics.structural_similarity(real_mel, recon_mel, data_range=2)\n",
    "    \n",
    "    return psnr, ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-player",
   "metadata": {},
   "source": [
    "Running B2A forward pass, displaying and evaluating reconstruction, and saving generated mel to wavenet dir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acquired-lightning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59c4490d8544e0e8c29418ead42a00e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Evaluation Metrics ====\n",
      "Average PSNR:  8.942719154842187\n",
      "Average SSIM:  0.21087500472898835\n"
     ]
    }
   ],
   "source": [
    "def eval_B2A(wavmels_B):\n",
    "    \n",
    "    psnr = []\n",
    "    ssim = []\n",
    "    \n",
    "    # Holds numpy original wavs and style transfered mels\n",
    "    path_gen = '../WAVENET/egs/gaussian/dump/lj/logmelspectrogram/norm/'+n+'_B2A/'\n",
    "    if not os.path.exists(path_gen): os.makedirs(path_gen)\n",
    "        \n",
    "    # Holds mel spectro image outputs, and .npy metric arrays\n",
    "    path_pool= path+'/test_B2A/'\n",
    "    if not os.path.exists(path_pool): os.makedirs(path_pool)\n",
    "    \n",
    "    traintxt = '../WAVENET/egs/gaussian/dump/lj/logmelspectrogram/norm/'+n+'_B2A/train.txt'\n",
    "    open(traintxt, 'w').close() # Clears file from any previous runs\n",
    "    f = open(traintxt, 'a')  # Opens file for appending\n",
    "    \n",
    "    for i, wavmel in tqdm(enumerate(wavmels_B)):\n",
    "        mel = np.load(test_path_B+wavmel['mel'].decode())\n",
    "        real_mel_B, recon_mel_B, fake_mel_A = forward_B2A(mel) # B2A_logvar if logvar\n",
    "        \n",
    "        # Save generated mel for wavenet evaluation\n",
    "        melstr = 'fake_mel_A_'+str(i)+'.npy'\n",
    "        np.save(path_gen+melstr, fake_mel_A)\n",
    "\n",
    "        # Save original wav for wavenet evaluation\n",
    "        wavstr = wavmel['wav'].decode()\n",
    "        wavrandom = np.load(test_path_B+wavstr)\n",
    "        np.save(path_gen+wavstr, wavrandom) \n",
    "\n",
    "        f.write(wavstr+'|'+melstr+'|128|dummy\\n')  # for train.txt in wavenet\n",
    "        \n",
    "        # Save image of the test case\n",
    "        show_mel_transfer(real_mel_B, recon_mel_B, fake_mel_A, path_pool+'a_fake_'+str(i)+'.png')\n",
    "        \n",
    "        # Compute psnr and ssim\n",
    "        p, s = compute_psnr_ssim(real_mel_B, recon_mel_B)\n",
    "        psnr.append(p)\n",
    "        ssim.append(s)\n",
    "        \n",
    "    np.save(path_pool+'psnr.npy',np.array(psnr))\n",
    "    np.save(path_pool+'ssim.npy',np.array(ssim))\n",
    "    \n",
    "    print('==== Evaluation Metrics ====')\n",
    "    print('Average PSNR: ', np.mean(psnr))\n",
    "    print('Average SSIM: ', np.mean(ssim))\n",
    "        \n",
    "    return\n",
    "            \n",
    "eval_B2A(wavmels_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-clerk",
   "metadata": {},
   "source": [
    "Running A2B forward pass, displaying, evaluating reconstruction, and saving generated mel to wavenet dir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pleasant-singer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3b6c23896e4309802642fff8e5297e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Evaluation Metrics ====\n",
      "Average PSNR:  10.562554477926216\n",
      "Average SSIM:  0.2184385309261923\n"
     ]
    }
   ],
   "source": [
    "def eval_A2B(wavemels_A):\n",
    "    \n",
    "    psnr = []\n",
    "    ssim = []\n",
    "    \n",
    "    # Holds numpy original wavs and style transfered mels\n",
    "    path_gen = '../WAVENET/egs/gaussian/dump/lj/logmelspectrogram/norm/'+n+'_A2B/'\n",
    "    if not os.path.exists(path_gen): os.makedirs(path_gen)\n",
    "        \n",
    "    # Holds mel spectro image outputs, and .npy metric arrays\n",
    "    path_pool= path+'/test_A2B/'\n",
    "    if not os.path.exists(path_pool): os.makedirs(path_pool)\n",
    "    \n",
    "    traintxt = '../WAVENET/egs/gaussian/dump/lj/logmelspectrogram/norm/'+n+'_A2B/train.txt'\n",
    "    open(traintxt, 'w').close() # Clears file from any previous runs\n",
    "    f = open(traintxt, 'a')  # Opens file for appending\n",
    "    \n",
    "    for i, wavmel in tqdm(enumerate(wavmels_A)):\n",
    "        mel = np.load(test_path_A+wavmel['mel'].decode())\n",
    "        real_mel_A, recon_mel_A, fake_mel_B = forward_A2B(mel)  # A2B_logvar if logvar\n",
    "\n",
    "        # Save generated mel for wavenet evaluation\n",
    "        melstr = 'fake_mel_B_'+str(i)+'.npy'\n",
    "        np.save(path_gen+melstr, fake_mel_B)\n",
    "\n",
    "        # Save original wav also for wavenet evalutation\n",
    "        wavstr = wavmel['wav'].decode()\n",
    "        wavrandom = np.load(test_path_A+wavstr)\n",
    "        np.save(path_gen+wavstr, wavrandom) \n",
    "            \n",
    "        f.write(wavstr+'|'+melstr+'|128|dummy\\n')  # for train.txt in wavenet\n",
    "        \n",
    "        # Save image of the test case\n",
    "        show_mel_transfer(real_mel_A, recon_mel_A, fake_mel_B, path_pool+'b_fake_'+str(i)+'.png')\n",
    "        \n",
    "        # Compute psnr and ssim\n",
    "        p, s = compute_psnr_ssim(real_mel_A, recon_mel_A)\n",
    "        psnr.append(p)\n",
    "        ssim.append(s)\n",
    "        \n",
    "    np.save(path_pool+'psnr.npy',np.array(psnr))\n",
    "    np.save(path_pool+'ssim.npy',np.array(ssim))\n",
    "    \n",
    "    print('==== Evaluation Metrics ====')\n",
    "    print('Average PSNR: ', np.mean(psnr))\n",
    "    print('Average SSIM: ', np.mean(ssim))\n",
    "        \n",
    "eval_A2B(wavmels_A)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
