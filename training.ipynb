{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "documented-tattoo",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "supreme-judges",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "from utility import load_pickle, save_pickle, show_mel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-static",
   "metadata": {},
   "source": [
    "# Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-plaintiff",
   "metadata": {},
   "source": [
    "Model design and training made following Albadawi 2020, and some open source github repos and tutorials:\n",
    "- https://github.com/liusongxiang/StarGAN-Voice-Conversion/blob/master/model.py\n",
    "- https://github.com/pritishyuvraj/Voice-Conversion-GAN/blob/master/model.py\n",
    "- https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "- https://github.com/Lornatang/CycleGAN-PyTorch/blob/master/cyclegan_pytorch/models.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-chicken",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-suffering",
   "metadata": {},
   "source": [
    "Creating the residual block for the encoder. Instance norm 2d normalises samples with respect to them self rather than all neighbouring samples in a batch (as is done in batch normalization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "referenced-insulin",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(dim_in, dim_out, kernel_size=4, bias=False),\n",
    "            nn.InstanceNorm2d(dim_out),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(dim_out, dim_out, kernel_size=4, bias=False),\n",
    "            nn.InstanceNorm2d(dim_out))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.main(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-adult",
   "metadata": {},
   "source": [
    "The rational for the encoder is to rid of all the non-timbral related information in its dimensionality reduction to the latent space. The generator then builds up the new voice from the rich latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "coral-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "         \n",
    "        l = []\n",
    "        \n",
    "        # Initial linear convolutional mapping\n",
    "        l.append(nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=7, bias=False), \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2)))\n",
    "        \n",
    "        # Non-linear mapping convolutional layers\n",
    "        l.append(nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=4, bias=False, stride=2), \n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2)))\n",
    "        \n",
    "        l.append(nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=4, bias=False, stride=2),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2)))\n",
    "                 \n",
    "        # Residual blocks with skip connections for bottleneck\n",
    "        l.append(ResidualBlock(512, 1024))\n",
    "         \n",
    "        # OLD: Starting with less residual blocks due to memory\n",
    "        # l.append(ResidualBlock(512, 1024))\n",
    "        # l.append(ResidualBlock(1024, 1156))\n",
    "        # l.append(ResidualBlock(1156, 1280)) \n",
    "     \n",
    "        self.main = nn.Sequential(*l)\n",
    "        \n",
    "        # VAE bottleneck\n",
    "        self.mu = nn.Linear(1024, 128)\n",
    "        self.logvar = nn.Linear(1024, 128)\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.main(x)  \n",
    "        mu, logvar = self.mu(out), self.logvar(out)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return z, mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-buffalo",
   "metadata": {},
   "source": [
    "Following Albadawi 2020, making the generator the reverse of the encoder for upsampling in a decoder-like manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "horizontal-humidity",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        l = []\n",
    "        \n",
    "        l.append(ResidualBlock(128, 512))  \n",
    "        \n",
    "        # OLD: Starting with less residual blocks due to memory\n",
    "        # l.append(ResidualBlock(1156, 1024))\n",
    "        # l.append(ResidualBlock(1024, 512)) \n",
    "        \n",
    "        # Non-linear mapping convolutional layers\n",
    "        l.append(nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=4, bias=False, stride=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2)))\n",
    "        \n",
    "        l.append(nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, bias=False, stride=2), \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2)))\n",
    "        \n",
    "        # Final linear convolutional mapping \n",
    "        l.append(nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 128, kernel_size=7, bias=False), \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Tanh()))  # wrt DCGAN\n",
    "        \n",
    "        self.main = nn.Sequential(*l)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.main(x)             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-ecuador",
   "metadata": {},
   "source": [
    "Discriminator is downsampling to a feature space for classification. Followed DCGAN intuition. Strided convolutions with ReLU based activations, and non strided convolution for the last fifth layer with a Sigmoid activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "plain-salmon",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        l = []\n",
    "        \n",
    "        l.append(nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=4, bias=False, stride=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2)))\n",
    "        \n",
    "        l.append(nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=4, bias=False, stride=2),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2)))\n",
    "        \n",
    "        l.append(nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, kernel_size=4, bias=False, stride=2),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.2)))\n",
    "        \n",
    "        l.append(nn.Sequential(\n",
    "            nn.Conv2d(1024, 1280, kernel_size=4, bias=False, stride=2),\n",
    "            nn.BatchNorm2d(1280),\n",
    "            nn.LeakyReLU(0.2)))\n",
    "                \n",
    "        l.append(nn.Sequential(\n",
    "            nn.Conv2d(1280, 1, kernel_size=4, bias=False),\n",
    "            nn.BatchNorm2d(1280),\n",
    "            nn.Sigmoid()))  # wrt DCGAN\n",
    "        \n",
    "        self.main = nn.Sequential(*l)\n",
    "         \n",
    "    def forward(self, x):\n",
    "        return self.main(x)         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-reminder",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-consortium",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "august-burner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training control\n",
    "max_epochs = 2\n",
    "max_duplets = 2 \n",
    "batch_size = 2\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# Regularisation\n",
    "lambda_cycle = 10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-campbell",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-alfred",
   "metadata": {},
   "source": [
    "Loading data and shuffling it and converting to torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "southeast-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading\n",
    "melset_7_128 = load_pickle('pool/melset_7_128.pickle')\n",
    "melset_4_128 = load_pickle('pool/melset_4_128.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "challenging-pharmaceutical",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "\n",
    "# Shuffling melspectrograms\n",
    "melset_7_128 = rng.permutation(np.array(melset_7_128))\n",
    "melset_4_128 = rng.permutation(np.array(melset_4_128))\n",
    "\n",
    "# Torch conversion\n",
    "melset_7_128 = torch.from_numpy(melset_7_128)\n",
    "melset_4_128 = torch.from_numpy(melset_4_128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-commons",
   "metadata": {},
   "source": [
    "### Model Instantiation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-buffalo",
   "metadata": {},
   "source": [
    "Following Albadawi 2020, unlike the other models, there is only one universal encoder in attempt to train it to rid of frequency and loudness information across speakers.\n",
    "\n",
    "The first residual block of each generator was common in Albadawi 2020. For simplicity, the first ecoding residual block is not individual to each decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "placed-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' # torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Shared encoder model (with partial decoding)\n",
    "E = Encoder().to(device)\n",
    "\n",
    "# Generator and Discriminator for Speaker A to B\n",
    "G_A2B = Generator().to(device)\n",
    "D_B = Discriminator().to(device)\n",
    "\n",
    "# Generator and Discriminator for Speaker B to A\n",
    "G_B2A = Generator().to(device)\n",
    "D_A = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-bacon",
   "metadata": {},
   "source": [
    "### Training Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-account",
   "metadata": {},
   "source": [
    "Initialise weights from dist with mu=0, s=0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-reset",
   "metadata": {},
   "outputs": [],
   "source": [
    "E.apply(weights_init)\n",
    "G_A2B.apply(weights_init)\n",
    "G_B2A.apply(weights_init)\n",
    "D_A.apply(weights_init)\n",
    "D_B.apply(weights_init)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-chase",
   "metadata": {},
   "source": [
    "Keeping an experience roleplay buffer for training discriminator on previous iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-spyware",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, max_size=50):\n",
    "        assert (max_size > 0), \"Empty buffer or trying to create a black hole. Be careful.\"\n",
    "        self.max_size = max_size\n",
    "        self.data = []\n",
    "\n",
    "    def push_and_pop(self, data):\n",
    "        to_return = []\n",
    "        for element in data.data:\n",
    "            element = torch.unsqueeze(element, 0)\n",
    "            if len(self.data) < self.max_size:\n",
    "                self.data.append(element)\n",
    "                to_return.append(element)\n",
    "            else:\n",
    "                if random.uniform(0, 1) > 0.5:\n",
    "                    i = random.randint(0, self.max_size - 1)\n",
    "                    to_return.append(self.data[i].clone())\n",
    "                    self.data[i] = element\n",
    "                else:\n",
    "                    to_return.append(element)\n",
    "        return torch.cat(to_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_A_buffer = ReplayBuffer()\n",
    "fake_B_buffer = ReplayBuffer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-charlotte",
   "metadata": {},
   "source": [
    "### Objective Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-search",
   "metadata": {},
   "source": [
    "MSE instead of BCE for adversarial loss making it a Least Squares GAN. Aims to minimize vanishing gradients by making it less discrete, done following CycleGAN implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising optimizers\n",
    "optim_E = torch.optim.Adam(E.parameters(), lr=learning_rate)\n",
    "optim_G = torch.optim.Adam(itertools.chain(G_A2B.parameters(), G_B2A.parameters()),lr=learning_rate)\n",
    "optim_D_A = torch.optim.Adam(D_A.parameters(), lr=learning_rate)\n",
    "optim_D_B = torch.optim.Adam(D_B.parameters(), lr=learning_rate)\n",
    "\n",
    "# Inializing criterions\n",
    "loss_adversarial = torch.nn.MSELoss().to(device)\n",
    "loss_cycle = torch.nn.L1Loss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-verse",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-vegetable",
   "metadata": {},
   "source": [
    "Training loop implemented based on Albadawi 2020 for theory and CycleGAN for implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-electronics",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in trange(max_epochs):\n",
    "    for j in range(0, max_duplets, batch_size):\n",
    "        \n",
    "        # Loading real samples from each speaker in batches\n",
    "        real_mel_A = melset_7_128[j:j+batch_size].to(device)\n",
    "        real_mel_B = melset_4_128[j:j+batch_size].to(device)\n",
    "\n",
    "        # Real data labelled 1, fake data labelled 0\n",
    "        batch_size = real_mel_A.size(0)\n",
    "        real_label = torch.full((batch_size, 1), 1, device=device, dtype=torch.float32)\n",
    "        fake_label = torch.full((batch_size, 1), 0, device=device, dtype=torch.float32)\n",
    "        \n",
    "        # =====================================================\n",
    "        #            Encoders and Decoding Generators update\n",
    "        # =====================================================\n",
    "\n",
    "        # Resetting gradients\n",
    "        optim_E.zero_grad()\n",
    "        optim_G.zero_grad()   \n",
    "\n",
    "        # Forward pass for B to A\n",
    "        latent_mel_A, mu_A, logvar_A = E(real_mel_A)\n",
    "        fake_mel_A = G_B2A(latent_mel_B)\n",
    "        fake_output_A = D_A(fake_mel_A)\n",
    "        recon_mel_B = G_A2B(fake_mel_A)  # cyclic reconstuction\n",
    "        \n",
    "        # Forward pass for A to B\n",
    "        latent_mel_B, mu_B, logvar_B = E(real_mel_B)\n",
    "        fake_mel_B = G_A2B(latent_mel_B)\n",
    "        fake_output_B = D_B(fake_mel_B)\n",
    "        recon_mel_A = G_B2A(fake_mel_B)  # cyclic reconstuction\n",
    "        \n",
    "        # Encoding loss A and B\n",
    "        kld_A = -0.5 * torch.sum(1 + logvar_A - mu_A.pow(2) - logvar_A.exp())\n",
    "        mse_A = (recon_mel_A - real_mel_A).pow(2).mean()\n",
    "        loss_VAE_A = kld_A + mse_A\n",
    "        \n",
    "        kld_B = -0.5 * torch.sum(1 + logvar_B - mu_B.pow(2) - logvar_B.exp())\n",
    "        mse_B = (recon_mel_B - real_mel_B).pow(2).mean()\n",
    "        loss_VAE_B = kld_B + mse_B\n",
    "        \n",
    "        errVAE = (loss_VAE_A + loss_VAE_B) / 2\n",
    "        errVAE.backward()\n",
    "        optim_E.step()\n",
    "        \n",
    "        # GAN loss\n",
    "        loss_GAN_B2A = loss_adversarial(fake_mel_A, real_label)\n",
    "        loss_GAN_A2B = loss_adversarial(fake_mel_B, real_label)\n",
    "        \n",
    "        # Cyclic loss\n",
    "        loss_cycle_ABA = cycle_loss(recon_mel_A, real_mel_A) * lambda_cycle\n",
    "        loss_cycle_BAB = cycle_loss(recon_mel_B, real_mel_B) * lambda_cycle\n",
    "        \n",
    "        # Backward pass and update all  \n",
    "        errG = loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB\n",
    "        errG.backward()\n",
    "        optim_G.step()\n",
    "        \n",
    "        \n",
    "        # =====================================================\n",
    "        #                   Discriminators update\n",
    "        # =====================================================\n",
    "        \n",
    "        # Resetting gradients\n",
    "        optim_D_A.zero_grad()\n",
    "        optim_D_B.zero_grad()\n",
    "        \n",
    "        # Forward pass D_A\n",
    "        real_out_A = D_A(real_mel_A)\n",
    "        fake_mel_A = fake_A_buffer.push_and_pop(fake_mel_A)\n",
    "        fake_out_A = D_A(fake_mel_A.detach())\n",
    "        \n",
    "        loss_D_real_A = adversarial_loss(real_out_A, real_label)\n",
    "        loss_D_fake_A = adversarial_loss(fake_out_A, fake_label)\n",
    "        errD_A = (loss_D_real_A + loss_D_fake_A) / 2\n",
    "        \n",
    "        # Forward pass D_B\n",
    "        real_out_B = D_B(real_mel_B)\n",
    "        fake_mel_B = fake_B_buffer.push_and_pop(fake_mel_B)\n",
    "        fake_out_B = D_B(fake_mel_B.detach())\n",
    "        \n",
    "        loss_D_real_B = adversarial_loss(real_out_B, real_label)\n",
    "        loss_D_fake_B = adversarial_loss(fake_out_B, fake_label)\n",
    "        errD_B = (loss_D_real_B + loss_D_fake_B) / 2\n",
    "        \n",
    "        # Backward pass and update all\n",
    "        errD_A.backward()\n",
    "        errD_B.backward()\n",
    "        optim_D_A.step()\n",
    "        optim_D_B.step() \n",
    "        \n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "        # TODO: Image saving\n",
    "        \n",
    "    # TODO: Checkpoint after each epoch\n",
    "\n",
    "        \n",
    "# TODO: Save last checkpoint       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
