{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "documented-tattoo",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "supreme-judges",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "from utility import load_pickle, save_pickle, show_mel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-static",
   "metadata": {},
   "source": [
    "# Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-plaintiff",
   "metadata": {},
   "source": [
    "Model design and training made following Albadawi 2020, and some open source github repos and tutorials:\n",
    "- https://github.com/liusongxiang/StarGAN-Voice-Conversion/blob/master/model.py\n",
    "- https://github.com/pritishyuvraj/Voice-Conversion-GAN/blob/master/model.py\n",
    "- https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "- https://github.com/Lornatang/CycleGAN-PyTorch/blob/master/cyclegan_pytorch/models.py\n",
    "- https://github.com/seangal/dcgan_vae_pytorch/blob/master/main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-chicken",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-suffering",
   "metadata": {},
   "source": [
    "Creating the residual block for the encoder. Instance norm 2d normalises samples with respect to them self rather than all neighbouring samples in a batch (as is done in batch normalization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "referenced-insulin",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim_in):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.ReflectionPad2d(2),\n",
    "            nn.Conv2d(dim_in, dim_in, kernel_size=4, bias=False),\n",
    "            nn.InstanceNorm2d(dim_in),\n",
    "            nn.LeakyReLU(0.2, inplace=True))\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(dim_in, dim_in, kernel_size=4, bias=False),\n",
    "            nn.InstanceNorm2d(dim_in))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        y = self.conv2(y)\n",
    "        return x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-adult",
   "metadata": {},
   "source": [
    "The rational for the encoder is to rid of all the non-timbral related information in its dimensionality reduction to the latent space. The generator then builds up the new voice from the rich latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "coral-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # Initial linear convolutional mapping\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 128, kernel_size=7, bias=False), \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        # Non-linear mapping convolutional layers\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=4, bias=False, stride=2), \n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        self.conv3 =nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=4, bias=False, stride=2),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        self.conv4 =nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, kernel_size=4, bias=False, stride=2),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.2)) \n",
    "                 \n",
    "        # Residual blocks with skip connections for bottleneck\n",
    "        self.res5 = ResidualBlock(1024)\n",
    "        self.mu6 = ResidualBlock(1024)\n",
    "        self.logvar6 = ResidualBlock(1024)\n",
    "        \n",
    "        # OLD: Starting with less residual blocks due to memory\n",
    "        # l.append(ResidualBlock(512, 1024))\n",
    "        # l.append(ResidualBlock(1024, 1156))\n",
    "        # l.append(ResidualBlock(1156, 1280)) \n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "        \n",
    "    def forward(self, x):     \n",
    "        \n",
    "        # Main layers\n",
    "        x = self.conv1(x)      \n",
    "        x = self.conv2(x)      \n",
    "        x = self.conv3(x)        \n",
    "        x = self.conv4(x)     \n",
    "        x = self.res5(x)     \n",
    "        \n",
    "        # Bottleneck\n",
    "        mu = self.mu6(x)\n",
    "        logvar = self.logvar6(x)   \n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return z, mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-buffalo",
   "metadata": {},
   "source": [
    "Following Albadawi 2020, making the generator the reverse of the encoder for upsampling in a decoder-like manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "horizontal-humidity",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.res1 = ResidualBlock(1024)  \n",
    "        \n",
    "        # OLD: Starting with less residual blocks due to memory\n",
    "        # l.append(ResidualBlock(1156, 1024))\n",
    "        # l.append(ResidualBlock(1024, 512)) \n",
    "        \n",
    "        # Non-linear mapping convolutional layers\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1024, 512, kernel_size=4, bias=False, stride=2),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=4, bias=False, stride=2), \n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, bias=False, stride=2), \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        # Final linear convolutional mapping \n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 1, kernel_size=11, bias=False), \n",
    "            nn.Tanh())  # wrt DCGAN\n",
    "                \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.res1(x)  \n",
    "        x = self.conv2(x) \n",
    "        x = self.conv3(x) \n",
    "        x = self.conv4(x) \n",
    "        x = self.conv5(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-ecuador",
   "metadata": {},
   "source": [
    "Discriminator is downsampling to a feature space for classification. Followed DCGAN intuition. Strided convolutions with ReLU based activations, and non strided convolution for the last fifth layer with a Sigmoid activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "plain-salmon",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=4, bias=False, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True))\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=4, bias=False, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True))\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=4, bias=False, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True))\n",
    "        \n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=4, bias=False, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True))\n",
    "                \n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1, kernel_size=8, bias=False),\n",
    "            nn.Sigmoid())  # wrt DCGAN\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        return x        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-reminder",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-consortium",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "august-burner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training control\n",
    "max_epochs = 2\n",
    "max_duplets = 3000\n",
    "batch_size = 4\n",
    "learning_rate = 0.0001\n",
    "\n",
    "assert max_duplets % batch_size == 0, 'Max sample pairs must be divisible by batch size!' \n",
    "\n",
    "# Regularisation\n",
    "lambda_cycle = 10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-campbell",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-alfred",
   "metadata": {},
   "source": [
    "Loading data and shuffling it and converting to torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "southeast-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading\n",
    "melset_7_128 = load_pickle('pool/melset_7_128.pickle')\n",
    "melset_4_128 = load_pickle('pool/melset_4_128.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "rural-sunglasses",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160 3386\n"
     ]
    }
   ],
   "source": [
    "print(len(melset_7_128), len(melset_4_128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "challenging-pharmaceutical",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "\n",
    "# Shuffling melspectrograms\n",
    "melset_7_128 = rng.permutation(np.array(melset_7_128))\n",
    "melset_4_128 = rng.permutation(np.array(melset_4_128))\n",
    "\n",
    "# Torch conversion\n",
    "melset_7_128 = torch.from_numpy(melset_7_128)\n",
    "melset_4_128 = torch.from_numpy(melset_4_128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-commons",
   "metadata": {},
   "source": [
    "### Model Instantiation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-buffalo",
   "metadata": {},
   "source": [
    "Following Albadawi 2020, unlike the other models, there is only one universal encoder in attempt to train it to rid of frequency and loudness information across speakers.\n",
    "\n",
    "The first residual block of each generator was common in Albadawi 2020. For simplicity, the first ecoding residual block is not individual to each decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "placed-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up memory if models previously initialised\n",
    "import gc\n",
    "if 'E' in globals(): del E \n",
    "if 'G_A2B' in globals(): del G_A2B\n",
    "if 'D_B' in globals(): del D_B \n",
    "if 'G_B2A' in globals(): del G_B2A\n",
    "if 'D_A' in globals(): del D_A\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = 'cuda' # torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Shared encoder model (with partial decoding)\n",
    "E = Encoder().to(device)\n",
    "\n",
    "# Generator and Discriminator for Speaker A to B\n",
    "G_A2B = Generator().to(device)\n",
    "D_B = Discriminator().to(device)\n",
    "\n",
    "# Generator and Discriminator for Speaker B to A\n",
    "G_B2A = Generator().to(device)\n",
    "D_A = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-bacon",
   "metadata": {},
   "source": [
    "### Training Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-account",
   "metadata": {},
   "source": [
    "Initialise weights from dist with mu=0, s=0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adjustable-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afraid-reset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "E.apply(weights_init)\n",
    "G_A2B.apply(weights_init)\n",
    "G_B2A.apply(weights_init)\n",
    "D_A.apply(weights_init)\n",
    "D_B.apply(weights_init)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-chase",
   "metadata": {},
   "source": [
    "Keeping an experience roleplay buffer for training discriminator on previous iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "seeing-spyware",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, max_size=50):\n",
    "        assert (max_size > 0), \"Empty buffer or trying to create a black hole. Be careful.\"\n",
    "        self.max_size = max_size\n",
    "        self.data = []\n",
    "\n",
    "    def push_and_pop(self, data):\n",
    "        to_return = []\n",
    "        for element in data.data:\n",
    "            element = torch.unsqueeze(element, 0)\n",
    "            if len(self.data) < self.max_size:\n",
    "                self.data.append(element)\n",
    "                to_return.append(element)\n",
    "            else:\n",
    "                if random.uniform(0, 1) > 0.5:\n",
    "                    i = random.randint(0, self.max_size - 1)\n",
    "                    to_return.append(self.data[i].clone())\n",
    "                    self.data[i] = element\n",
    "                else:\n",
    "                    to_return.append(element)\n",
    "        return torch.cat(to_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "quiet-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_A_buffer = ReplayBuffer()\n",
    "fake_B_buffer = ReplayBuffer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-charlotte",
   "metadata": {},
   "source": [
    "### Objective Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-search",
   "metadata": {},
   "source": [
    "MSE instead of BCE for adversarial loss making it a Least Squares GAN. Aims to minimize vanishing gradients by making it less discrete, done following CycleGAN implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "chinese-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising optimizers\n",
    "optim_E = torch.optim.Adam(E.parameters(), lr=learning_rate)\n",
    "optim_G = torch.optim.Adam(itertools.chain(G_A2B.parameters(), G_B2A.parameters()),lr=learning_rate)\n",
    "optim_D_A = torch.optim.Adam(D_A.parameters(), lr=learning_rate)\n",
    "optim_D_B = torch.optim.Adam(D_B.parameters(), lr=learning_rate)\n",
    "\n",
    "# Inializing criterions\n",
    "loss_adversarial = torch.nn.MSELoss().to(device)\n",
    "loss_cycle = torch.nn.L1Loss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-verse",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-vegetable",
   "metadata": {},
   "source": [
    "Training loop implemented based on Albadawi 2020 for theory and CycleGAN for implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "labeled-electronics",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]/homes/rs002/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([4, 1, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "  0%|          | 0/2 [00:17<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-63c9c31f6be2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# Forward pass D_A\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mreal_out_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD_A\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_mel_A\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mfake_mel_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfake_A_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_and_pop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_mel_A\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mfake_out_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD_A\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_mel_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-21f1138af89d>\u001b[0m in \u001b[0;36mpush_and_pop\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mto_return\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mto_return\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "for i in trange(max_epochs):\n",
    "    for j in range(0, max_duplets, batch_size):\n",
    "        \n",
    "        # Loading real samples from each speaker in batches\n",
    "        real_mel_A = melset_7_128[j * batch_size : (j * batch_size) + batch_size].to(device)\n",
    "        real_mel_B = melset_4_128[j * batch_size : (j * batch_size) + batch_size].to(device)\n",
    "        \n",
    "        # Resizing to model tensors\n",
    "        real_mel_A = real_mel_A.view(batch_size, 1, 128, 128)\n",
    "        real_mel_B = real_mel_B.view(batch_size, 1, 128, 128)\n",
    "\n",
    "        # Real data labelled 1, fake data labelled 0\n",
    "        batch_size = real_mel_A.size(0)\n",
    "        real_label = torch.squeeze(torch.full((batch_size, 1), 1, device=device, dtype=torch.float32))\n",
    "        fake_label = torch.squeeze(torch.full((batch_size, 1), 0, device=device, dtype=torch.float32))\n",
    "        \n",
    "        # =====================================================\n",
    "        #            Encoders and Decoding Generators update\n",
    "        # =====================================================\n",
    "\n",
    "        # Resetting gradients\n",
    "        optim_E.zero_grad()\n",
    "        optim_G.zero_grad()   \n",
    "\n",
    "        # Forward pass for B to A\n",
    "        latent_mel_A, mu_A, logvar_A = E(real_mel_A)\n",
    "        fake_mel_A = G_B2A(latent_mel_A)\n",
    "        fake_output_A = torch.squeeze(D_A(fake_mel_A))\n",
    "        \n",
    "        # Cyclic reconstuction from fake A to B\n",
    "        latent_fake_A, mu_fake_A, logvar_fake_A = E(fake_mel_A)\n",
    "        recon_mel_B = G_A2B(latent_fake_A)  \n",
    "        \n",
    "        # Forward pass for A to B\n",
    "        latent_mel_B, mu_B, logvar_B = E(real_mel_B)\n",
    "        fake_mel_B = G_A2B(latent_mel_B)\n",
    "        fake_output_B = torch.squeeze(D_B(fake_mel_B))\n",
    "        \n",
    "        # Cyclic reconstuction from fake B to A\n",
    "        latent_fake_B, mu_fake_B, logvar_fake_B = E(fake_mel_B)\n",
    "        recon_mel_A = G_B2A(latent_fake_B)  \n",
    "        \n",
    "        # Encoding loss A and B\n",
    "        kld_A = -0.5 * torch.sum(1 + logvar_A - mu_A.pow(2) - logvar_A.exp())\n",
    "        mse_A = (recon_mel_A - real_mel_A).pow(2).mean()\n",
    "        loss_VAE_A = kld_A + mse_A\n",
    "        \n",
    "        kld_B = -0.5 * torch.sum(1 + logvar_B - mu_B.pow(2) - logvar_B.exp())\n",
    "        mse_B = (recon_mel_B - real_mel_B).pow(2).mean()\n",
    "        loss_VAE_B = kld_B + mse_B\n",
    "        \n",
    "        errVAE = (loss_VAE_A + loss_VAE_B) / 2\n",
    "        errVAE.backward(retain_graph=True)  # retain graph so other losses can update in same graph\n",
    "        optim_E.step()\n",
    "        \n",
    "        # GAN loss\n",
    "        loss_GAN_B2A = loss_adversarial(fake_output_A, real_label)\n",
    "        loss_GAN_A2B = loss_adversarial(fake_output_B, real_label)\n",
    "        \n",
    "        # Cyclic loss\n",
    "        loss_cycle_ABA = loss_cycle(recon_mel_A, real_mel_A) * lambda_cycle\n",
    "        loss_cycle_BAB = loss_cycle(recon_mel_B, real_mel_B) * lambda_cycle\n",
    "        \n",
    "        # Backward pass and update all  \n",
    "        errG = loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB\n",
    "        errG.backward()\n",
    "        optim_G.step()\n",
    "        \n",
    "        \n",
    "        # =====================================================\n",
    "        #                   Discriminators update\n",
    "        # =====================================================\n",
    "        \n",
    "        # Resetting gradients\n",
    "        optim_D_A.zero_grad()\n",
    "        optim_D_B.zero_grad()\n",
    "        \n",
    "        # Forward pass D_A\n",
    "        real_out_A = D_A(real_mel_A)\n",
    "        fake_mel_A = fake_A_buffer.push_and_pop(fake_mel_A)\n",
    "        fake_out_A = D_A(fake_mel_A.detach())\n",
    "        \n",
    "        loss_D_real_A = loss_adversarial(real_out_A, real_label)\n",
    "        loss_D_fake_A = loss_adversarial(fake_out_A, fake_label)\n",
    "        errD_A = (loss_D_real_A + loss_D_fake_A) / 2\n",
    "        \n",
    "        # Forward pass D_B\n",
    "        real_out_B = D_B(real_mel_B)\n",
    "        fake_mel_B = fake_B_buffer.push_and_pop(fake_mel_B)\n",
    "        fake_out_B = D_B(fake_mel_B.detach())\n",
    "        \n",
    "        loss_D_real_B = loss_adversarial(real_out_B, real_label)\n",
    "        loss_D_fake_B = loss_adversarial(fake_out_B, fake_label)\n",
    "        errD_B = (loss_D_real_B + loss_D_fake_B) / 2\n",
    "        \n",
    "        # Backward pass and update all\n",
    "        errD_A.backward()\n",
    "        errD_B.backward()\n",
    "        optim_D_A.step()\n",
    "        optim_D_B.step() \n",
    "        \n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "        # TODO: Image saving\n",
    "        \n",
    "    # TODO: Checkpoint after each epoch\n",
    "\n",
    "        \n",
    "# TODO: Save last checkpoint       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
