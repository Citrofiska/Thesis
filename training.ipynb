{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "documented-tattoo",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "supreme-judges",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "from utility import load_pickle, save_pickle, show_mel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-postcard",
   "metadata": {},
   "source": [
    "# Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-premises",
   "metadata": {},
   "source": [
    "Model design and training made following Albadawi 2020, and some open source github repos and tutorials:\n",
    "- https://github.com/liusongxiang/StarGAN-Voice-Conversion/blob/master/model.py\n",
    "- https://github.com/pritishyuvraj/Voice-Conversion-GAN/blob/master/model.py\n",
    "- https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "- https://github.com/Lornatang/CycleGAN-PyTorch/blob/master/cyclegan_pytorch/models.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-chicken",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-suffering",
   "metadata": {},
   "source": [
    "Creating the residual block for the encoder. Instance norm 2d normalises samples with respect to them self rather than all neighbouring samples in a batch (as is done in batch normalization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "referenced-insulin",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(dim_in, dim_out, kernel_size=4, bias=False),\n",
    "            nn.InstanceNorm2d(dim_out),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(dim_out, dim_out, kernel_size=4, bias=False),\n",
    "            nn.InstanceNorm2d(dim_out))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.main(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-adult",
   "metadata": {},
   "source": [
    "The rational for the encoder is to rid of all the non-timbral related information in its dimensionality reduction to the latent space. The generator then builds up the new voice from the rich latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "coral-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "         \n",
    "        l = []\n",
    "        \n",
    "        # Initial linear convolutional mapping\n",
    "        l.append(nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=7, bias=False), \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2)))\n",
    "        \n",
    "        # Non-linear mapping convolutional layers\n",
    "        l.append(nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=4, bias=False, stride=2), \n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2)))\n",
    "        \n",
    "        l.append(nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=4, bias=False, stride=2),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2)))\n",
    "                 \n",
    "        # Residual blocks with skip connections for bottleneck\n",
    "        l.append(ResidualBlock(512, 1024))\n",
    "         \n",
    "        # OLD: Starting with less residual blocks due to memory\n",
    "        # l.append(ResidualBlock(512, 1024))\n",
    "        # l.append(ResidualBlock(1024, 1156))\n",
    "        # l.append(ResidualBlock(1156, 1280)) \n",
    "        \n",
    "        self.main = nn.Sequential(*l)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.main(x)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-buffalo",
   "metadata": {},
   "source": [
    "Following Albadawi 2020, making the generator the reverse of the encoder for upsampling in a decoder-like manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "horizontal-humidity",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, sharedResBlock):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        l = []\n",
    "                \n",
    "        # Residual blocks for expanding from latent space       \n",
    "        l.append(sharedResBlock) \n",
    "        \n",
    "        # OLD: Starting with less residual blocks due to memory\n",
    "        # l.append(sharedResBlock)  # First res block shared across G\n",
    "        # l.append(ResidualBlock(1156, 1024))\n",
    "        # l.append(ResidualBlock(1024, 512)) \n",
    "        \n",
    "        # Non-linear mapping convolutional layers\n",
    "        l.append(nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=4, bias=False, stride=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2)))\n",
    "        \n",
    "        l.append(nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, bias=False, stride=2), \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2)))\n",
    "        \n",
    "        # Final linear convolutional mapping \n",
    "        l.append(nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 128, kernel_size=7, bias=False), \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Tanh()))  # wrt DCGAN\n",
    "        \n",
    "        self.main = nn.Sequential(*l)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.main(x)             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-ecuador",
   "metadata": {},
   "source": [
    "Discriminator is downsampling to a feature space for classification. Followed DCGAN intuition. Strided convolutions with ReLU based activations, and non strided convolution for the last fifth layer with a Sigmoid activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "plain-salmon",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        l = []\n",
    "        \n",
    "        l.append(nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=4, bias=False, stride=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2)))\n",
    "        \n",
    "        l.append(nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=4, bias=False, stride=2),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2)))\n",
    "        \n",
    "        l.append(nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, kernel_size=4, bias=False, stride=2),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.2)))\n",
    "        \n",
    "        l.append(nn.Sequential(\n",
    "            nn.Conv2d(1024, 1280, kernel_size=4, bias=False, stride=2),\n",
    "            nn.BatchNorm2d(1280),\n",
    "            nn.LeakyReLU(0.2)))\n",
    "                \n",
    "        l.append(nn.Sequential(\n",
    "            nn.Conv2d(1280, 1, kernel_size=4, bias=False),\n",
    "            nn.BatchNorm2d(1280),\n",
    "            nn.Sigmoid()))  # wrt DCGAN\n",
    "        \n",
    "        self.main = nn.Sequential(*l)\n",
    "         \n",
    "    def forward(self, x):\n",
    "        return self.main(x)         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-reminder",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-consortium",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "august-burner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training control\n",
    "max_epochs = 2\n",
    "max_duplets = 2 \n",
    "batch_size = 2\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# Regularisation\n",
    "lambda_cycle = 10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "running-grain",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-alfred",
   "metadata": {},
   "source": [
    "Loading data and shuffling it and converting to torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "southeast-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading\n",
    "melset_7_128 = load_pickle('pool/melset_7_128.pickle')\n",
    "melset_4_128 = load_pickle('pool/melset_4_128.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "challenging-pharmaceutical",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "\n",
    "# Shuffling melspectrograms\n",
    "melset_7_128 = rng.permutation(np.array(melset_7_128))\n",
    "melset_4_128 = rng.permutation(np.array(melset_4_128))\n",
    "\n",
    "# Torch conversion\n",
    "melset_7_128 = torch.from_numpy(melset_7_128)\n",
    "melset_4_128 = torch.from_numpy(melset_4_128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-commons",
   "metadata": {},
   "source": [
    "### Model Instantiation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-buffalo",
   "metadata": {},
   "source": [
    "Following Albadawi 2020, unlike the other models, there is only one universal encoder in attempt to train it to rid of frequency and loudness information across speakers.\n",
    "\n",
    "The first residual block of each generator is shared because of the shared latent space assumption coming from the universal encoder. This is to further encourage a general latent space mapping focused on timbral aspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "placed-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' # torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Shared models\n",
    "E = Encoder().to(device)\n",
    "R = ResidualBlock(1024, 512)  # Shared first residual blocks across all Gs\n",
    "\n",
    "# OLD: Starting with less residual blocks due to memory\n",
    "# R = ResidualBlock(1280, 1156)\n",
    "\n",
    "# Generator and Discriminator for Speaker A to B\n",
    "G_A2B = Generator(R).to(device)\n",
    "D_B = Discriminator().to(device)\n",
    "\n",
    "# Generator and Discriminator for Speaker B to A\n",
    "G_B2A = Generator(R).to(device)\n",
    "D_A = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-clarity",
   "metadata": {},
   "source": [
    "### Training Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-russian",
   "metadata": {},
   "source": [
    "Initialise weights from dist with mu=0, s=0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "seventh-tournament",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "continental-bridges",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "E.apply(weights_init)\n",
    "R.apply(weights_init)\n",
    "G_A2B.apply(weights_init)\n",
    "G_B2A.apply(weights_init)\n",
    "D_A.apply(weights_init)\n",
    "D_B.apply(weights_init)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-smell",
   "metadata": {},
   "source": [
    "Keeping an experience roleplay buffer for training discriminator on previous iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "secret-cleveland",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, max_size=50):\n",
    "        assert (max_size > 0), \"Empty buffer or trying to create a black hole. Be careful.\"\n",
    "        self.max_size = max_size\n",
    "        self.data = []\n",
    "\n",
    "    def push_and_pop(self, data):\n",
    "        to_return = []\n",
    "        for element in data.data:\n",
    "            element = torch.unsqueeze(element, 0)\n",
    "            if len(self.data) < self.max_size:\n",
    "                self.data.append(element)\n",
    "                to_return.append(element)\n",
    "            else:\n",
    "                if random.uniform(0, 1) > 0.5:\n",
    "                    i = random.randint(0, self.max_size - 1)\n",
    "                    to_return.append(self.data[i].clone())\n",
    "                    self.data[i] = element\n",
    "                else:\n",
    "                    to_return.append(element)\n",
    "        return torch.cat(to_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "destroyed-spain",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_A_buffer = ReplayBuffer()\n",
    "fake_B_buffer = ReplayBuffer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-toolbox",
   "metadata": {},
   "source": [
    "### Objective Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-apparatus",
   "metadata": {},
   "source": [
    "MSE instead of BCE for adversarial loss making it a Least Squares GAN. Aims to minimize vanishing gradients by making it less discrete, done following CycleGAN implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "chinese-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising optimizers\n",
    "optim_E = torch.optim.Adam(E.parameters(), lr=learning_rate)\n",
    "optim_R = torch.optim.Adam(R.parameters(), lr=learning_rate)\n",
    "optim_G = torch.optim.Adam(itertools.chain(G_A2B.parameters(), G_B2A.parameters()),lr=learning_rate)\n",
    "optim_D_A = torch.optim.Adam(D_A.parameters(), lr=learning_rate)\n",
    "optim_D_B = torch.optim.Adam(D_B.parameters(), lr=learning_rate)\n",
    "\n",
    "# Loss functions\n",
    "loss_adversarial = torch.nn.MSELoss().to(device)\n",
    "loss_cycle = torch.nn.L1Loss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-verse",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-vegetable",
   "metadata": {},
   "source": [
    "Training loop implemented based on Albadawi 2020 for theory and CycleGAN for implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "labeled-electronics",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight 512 1024 4 4, but got 3-dimensional input of size [2, 128, 128] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-90cc7aa97f0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# ==== GAN loss ====\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# G mapping mel B to A\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mfake_mel_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG_B2A\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_mel_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mfake_output_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD_A\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_mel_A\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mloss_GAN_B2A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_adversarial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_mel_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-ac2acd5b3596>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-43e5e3124602>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    339\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 341\u001b[0;31m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[1;32m    342\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight 512 1024 4 4, but got 3-dimensional input of size [2, 128, 128] instead"
     ]
    }
   ],
   "source": [
    "for i in trange(max_epochs):\n",
    "    for j in range(0, max_duplets, batch_size):\n",
    "        \n",
    "        # Loading real samples from each speaker in batches\n",
    "        real_mel_A = melset_7_128[j:j+batch_size].to(device)\n",
    "        real_mel_B = melset_4_128[j:j+batch_size].to(device)\n",
    "\n",
    "        # Real data labelled 1, fake data labelled 0\n",
    "        batch_size = real_mel_A.size(0)\n",
    "        real_label = torch.full((batch_size, 1), 1, device=device, dtype=torch.float32)\n",
    "        fake_label = torch.full((batch_size, 1), 0, device=device, dtype=torch.float32)\n",
    "        \n",
    "        # =====================================================\n",
    "        #            Encoder and Decoding Generators update\n",
    "        # =====================================================\n",
    "\n",
    "        # Resetting gradients\n",
    "        optim_E.zero_grad()\n",
    "        optim_R.zero_grad()\n",
    "        optim_G.zero_grad()   \n",
    "\n",
    "        # Forward pass for B to A\n",
    "        latent_mel_A = E(real_mel_A)\n",
    "        post_latent_mel_A= R(latent_mel_A)\n",
    "        fake_mel_A = G_B2A(post_latent_mel_B)\n",
    "        fake_output_A = D_A(fake_mel_A)\n",
    "        recon_mel_A = G_B2A(fake_mel_B)  # reconstuction\n",
    "        \n",
    "        # Forward pass for A to B\n",
    "        latent_mel_B = E(real_mel_B)\n",
    "        post_latent_mel_B = R(latent_mel_B)\n",
    "        fake_mel_B = G_A2B(post_latent_mel_B)\n",
    "        fake_output_B = D_B(fake_mel_B)\n",
    "        recon_mel_B = G_A2B(fake_mel_A)  # reconstuction\n",
    "        \n",
    "        # VAE loss TODO\n",
    "        \n",
    "        # GAN loss\n",
    "        loss_GAN_B2A = loss_adversarial(fake_mel_A, real_label)\n",
    "        loss_GAN_A2B = loss_adversarial(fake_mel_B, real_label)\n",
    "        \n",
    "        # Cyclic loss\n",
    "        loss_cycle_ABA = cycle_loss(recon_mel_A, real_mel_A) * lambda_cycle\n",
    "        loss_cycle_BAB = cycle_loss(recon_mel_B, real_mel_B) * lambda_cycle\n",
    "        \n",
    "        # Update all  \n",
    "        loss_G = loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB\n",
    "        loss_G.backward()\n",
    "        optim_G.step()\n",
    "        \n",
    "        \n",
    "        # =====================================================\n",
    "        #                   Discriminators update\n",
    "        # =====================================================\n",
    "        \n",
    "        # Resetting gradients\n",
    "        optim_D_A.zero_grad()\n",
    "        optim_D_B.zero_grad()\n",
    "        \n",
    "        # ==== Updating D_A ====\n",
    "        # Real loss\n",
    "        real_out_A = D_A(real_mel_A)\n",
    "        loss_D_real_A = adversarial_loss(real_out_A, real_label)\n",
    "        \n",
    "        # Fake loss\n",
    "        fake_mel_A = fake_A_buffer.push_and_pop(fake_mel_A)\n",
    "        fake_out_A = D_A(fake_mel_A.detach())\n",
    "        loss_D_fake_A = adversarial_loss(fake_out_A, fake_label)\n",
    "        \n",
    "        # Combine and update\n",
    "        loss_D_A = (loss_D_real_A + loss_D_fake_A) / 2\n",
    "        D_A.backward()\n",
    "        optim_D_A.step()\n",
    "        \n",
    "        # ==== Updating D_B ====\n",
    "        # Real loss\n",
    "        real_out_B = D_B(real_mel_B)\n",
    "        loss_D_real_B = adversarial_loss(real_out_B, real_label)\n",
    "        \n",
    "        # Fake loss\n",
    "        fake_mel_B = fake_B_buffer.push_and_pop(fake_mel_B)\n",
    "        fake_out_B = D_B(fake_mel_B.detach())\n",
    "        loss_D_fake_B = adversarial_loss(fake_out_B, fake_label)\n",
    "        \n",
    "        # Combine and update\n",
    "        loss_D_B = (loss_D_real_B + loss_D_fake_B) / 2\n",
    "        D_B.backward()\n",
    "        optim_D_B.step() \n",
    "        \n",
    "        # TODO: Image saving\n",
    "        \n",
    "    # TODO: Checkpoint after each epoch\n",
    "\n",
    "        \n",
    "# TODO: Save last checkpoint       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
